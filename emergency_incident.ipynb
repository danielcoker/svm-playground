{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe414a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-macosx_10_13_x86_64.whl (7.2 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scikit-learn) (1.19.5)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-macosx_10_9_x86_64.whl (28.8 MB)\n",
      "     |████████████████▍               | 14.8 MB 8.1 kB/s eta 0:28:44\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 449, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py\", line 493, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py\", line 586, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 1012, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 874, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ssl.py\", line 631, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 164, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/cli/req_command.py\", line 205, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 339, in run\n",
      "    reqs, check_supported_wheels=not options.target_dir\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 93, in resolve\n",
      "    collected.requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 482, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 374, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 214, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 205, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
      "    version=version,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 287, in __init__\n",
      "    version=version,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 292, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/operations/prepare.py\", line 482, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/operations/prepare.py\", line 528, in _prepare_linked_requirement\n",
      "    link, req.source_dir, self._download, self.download_dir, hashes\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/operations/prepare.py\", line 217, in unpack_url\n",
      "    hashes=hashes,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/operations/prepare.py\", line 94, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/network/download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/cli/progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/network/utils.py\", line 87, in response_chunks\n",
      "    decode_content=False,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/urllib3/response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1677dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bf5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6adc3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = {0: \"Fire\", 1: \"Crime\", 2: \"Health\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16e7c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "data = {\n",
    "    \"Description\": [\n",
    "        \"There was a fire in the chemistry lab at the university.\",\n",
    "        \"A theft occurred in the electronics store last night.\",\n",
    "        \"A student had a medical emergency during a class.\",\n",
    "        \"I witnessed a hit-and-run accident on Main Street.\",\n",
    "        \"There was a large fight at the local bar involving multiple people.\",\n",
    "        \"A car crashed into a tree in the park.\",\n",
    "        \"Someone reported a suspicious package at the train station.\",\n",
    "        \"A person was assaulted in the park in the evening.\",\n",
    "        \"I found an injured bird in my backyard.\",\n",
    "        \"There's a gas leak in the apartment building.\",\n",
    "        \"A burglary took place at my neighbor's house.\",\n",
    "        \"I saw a person who fainted on the subway platform.\",\n",
    "        \"A dog is stuck in a tree in the park.\",\n",
    "        \"A drunk driver was seen swerving on the highway.\",\n",
    "        \"A building is on fire in the industrial area.\",\n",
    "        \"I spotted a missing child at the shopping mall.\",\n",
    "        \"A car was stolen from the parking lot of the grocery store.\",\n",
    "        \"There's a power outage in the neighborhood.\",\n",
    "        \"A fight broke out at a soccer game.\",\n",
    "        \"I heard gunshots in the neighborhood last night.\",\n",
    "    ],\n",
    "    \"IncidentCategory\": [0, 1, 2, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 1, 1, 0, 0, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc0403d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8765e9b4357e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Text preprocessing and Feature Extraction\n",
    "df[\"Description\"] = (\n",
    "    df[\"Description\"].str.replace(r\"[^\\w\\s]\", \"\").str.lower()\n",
    ")  # Convert to lowercase\n",
    "df[\"Description\"] = df[\"Description\"].str.replace(r\"[^\\w\\s]\", \"\")  # Remove punctuation\n",
    "\n",
    "# Tokenization\n",
    "df[\"Description\"] = df[\"Description\"].apply(nltk.word_tokenize)\n",
    "\n",
    "# Stop Word Removal\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "df[\"Description\"] = df[\"Description\"].apply(\n",
    "    lambda tokens: [word for word in tokens if word not in stop_words]\n",
    ")\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df[\"Description\"] = df[\"Description\"].apply(\n",
    "    lambda tokens: [stemmer.stem(word) for word in tokens]\n",
    ")\n",
    "\n",
    "# Join the tokens back into a single string\n",
    "df[\"Description\"] = df[\"Description\"].apply(' '.join)\n",
    "\n",
    "print(df[\"Description\"])\n",
    "\n",
    "# TF-IDF vectorization\n",
    "print(\"Vectorising the text...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"Description\"])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf_matrix,\n",
    "    df[\"IncidentCategory\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train the SVM Model\n",
    "print(\"Training the model...\")\n",
    "svm_classifier = SVC(kernel=\"linear\", C=1.0, random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "report = classification_report(y_test, predictions)\n",
    "print(report)\n",
    "\n",
    "# Test user provided response.\n",
    "user_description = \"I saw a person who fainted on the subway platform.\"\n",
    "\n",
    "# Preprocess the user's description to match the format used during training\n",
    "user_description = user_description.lower()  # Convert to lowercase\n",
    "user_description = user_description.replace(r\"[^\\w\\s]\", \"\")  # Remove punctuation\n",
    "\n",
    "# Vectorize the user's description using the same TF-IDF vectorizer used during training\n",
    "print(\"Vectorising the user's description...\")\n",
    "user_description_vector = tfidf_vectorizer.transform([user_description])\n",
    "\n",
    "# Predict the incident category using the trained model\n",
    "print(\"Predicting the incident category...\")\n",
    "predicted_category = svm_classifier.predict(user_description_vector)\n",
    "\n",
    "# Map the category label to the actual category name\n",
    "predicted_category_name = category_names[predicted_category[0]]\n",
    "\n",
    "# Display the prediction\n",
    "print(\n",
    "    \"Predicted Incident Category:\",\n",
    "    f\"{predicted_category_name} ({predicted_category[0]})\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
